{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Arabic Sign Language Recognition using CNNs\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This notebook details the implementation of a neural network using PyTorch to recognize Arabic Sign Language alphabets.  The goal is to contribute to improving accessibility and communication for those who use sign language.\n",
        "\n",
        "## 1. Dataset Details: ArASL\n",
        "\n",
        "This project utilizes the ArASL (Arabic Alphabets Sign Language Dataset).  This dataset contains images of hand signs representing the Arabic alphabet.\n",
        "\n",
        "- **Total Images:** 54,049\n",
        "- **Classes:** 32 (representing the Arabic alphabet)\n",
        "\n",
        "## 2. Label Representation\n",
        "\n",
        "Each image is associated with a numerical label representing a specific Arabic character.  These labels are integers ranging from 0 to 31.\n",
        "\n",
        "## 3. Character Mapping\n",
        "\n",
        "The mapping between numerical labels and corresponding Arabic characters is defined in the `mapping` variable (see code).  The mapping is also provided below for reference:\n",
        "\n",
        "0: 'seen', 1: 'zay', 2: 'aleff', 3: 'dal', 4: 'ta', 5: 'yaa', 6: 'fa', 7: 'ya', 8: 'khaa', 9: 'nun', 10: 'ha', 11: 'toot', 12: 'taa', 13: 'ra', 14: 'kaaf', 15: 'jeem', 16: 'laam', 17: 'la', 18: 'dhad', 19: 'dha', 20: 'waw', 21: 'meem', 22: 'al', 23: 'sheen', 24: 'haa', 25: 'thaa', 26: 'saad', 27: 'ghain', 28: 'ain', 29: 'thal', 30: 'gaaf', 31: 'bb'\n",
        "\n",
        "## 4. Reference\n",
        "\n",
        "Latif, G., Mohammad, N., Alghazo, J., AlKhalaf, R., & AlKhalaf, R. (2019). ARASL: Arabic Alphabets Sign Language Dataset. *Data in Brief*, 23, 103777. https://doi.org/10.1016/j.dib.2019.103777\n",
        "\n",
        "## 5. Instructions\n",
        "\n",
        "Your task is to do the following:\n",
        "\n",
        "1. **Data Loading:** Load the data into a PyTorch `Dataset` and create a `DataLoader` for efficient batch processing.\n",
        "2. **Classification Model:**\n",
        "    * Design and implement a CNN architecture for classification.\n",
        "    * Train the model using the `DataLoaders`.\n",
        "    * Evaluate the model and show the results.\n",
        "3. **Autoencoder:**\n",
        "    * Design and implement a CNN-based autoencoder (encoder-decoder).\n",
        "    * Train the autoencoder using the `DataLoader`.\n",
        "    * Evaluate the model and show the results.\n"
      ],
      "metadata": {
        "id": "PrjZIlXJPDHo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCpQaqwoH2Pk"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the required libraries (needed when running outside colab where the environment doesn't come pre-loaded with libraries)\n",
        "\n",
        "%pip install torch\n",
        "%pip install torchvision\n",
        "%pip install matplotlib\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "HBuuF9MJKjoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms.functional import to_tensor, to_pil_image, resize\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "gtV7omCIKq0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the dataset\n",
        "\n",
        "### Run the following cells to download the ArASL dataset."
      ],
      "metadata": {
        "id": "Gw5z1ZSoLlh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://data.mendeley.com/public-files/datasets/y7pckrw6z2/files/1efa0d6b-4d7f-4f58-9584-08f0488279ee/file_downloaded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqQxPwbp7TfV",
        "outputId": "01bdc7b5-f833-4a4b-a7b6-ec64582d45fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://data.mendeley.com/public-files/datasets/y7pckrw6z2/files/1efa0d6b-4d7f-4f58-9584-08f0488279ee/file_downloaded\n",
            "To: /content/file_downloaded\n",
            "100% 66.2M/66.2M [00:02<00:00, 25.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This challenge is made by [Hassan Alsayhah](https://www.linkedin.com/in/hassan-alsayhah-28a83a251/) & [Ali Alqutayfi](https://www.linkedin.com/in/ali-alqutayfi/)"
      ],
      "metadata": {
        "id": "fM8X1UxWv3Xq"
      }
    }
  ]
}